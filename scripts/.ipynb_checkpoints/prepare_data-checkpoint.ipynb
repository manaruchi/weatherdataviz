{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92e80a0d-b5da-4d4f-91e2-b90a9b446606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ wind_velocity.json created without wrf-python.\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "# Load WRF NetCDF file\n",
    "ds = xr.open_dataset(\"/Users/manaruchi/Desktop/WeatherDataViz/raw_data/AFCNWP_WRF_model_output_00UTC.nc\")\n",
    "\n",
    "# Direct access to variables\n",
    "u10 = ds[\"U10\"].isel(Time=0)     # shape: (y, x)\n",
    "v10 = ds[\"V10\"].isel(Time=0)\n",
    "lat = ds[\"XLAT\"].isel(Time=0)\n",
    "lon = ds[\"XLONG\"].isel(Time=0)\n",
    "\n",
    "# Prepare leaflet-velocity JSON format\n",
    "ny, nx = u10.shape\n",
    "\n",
    "data = {\n",
    "    \"header\": {\n",
    "        \"parameterUnit\": \"m/s\",\n",
    "        \"parameterNumber\": 2,\n",
    "        \"parameterNumberName\": \"eastward_wind\",\n",
    "        \"parameterCategory\": 2,\n",
    "        \"nx\": nx,\n",
    "        \"ny\": ny,\n",
    "        \"lo1\": float(lon[0, 0]),\n",
    "        \"la1\": float(lat[0, 0]),\n",
    "        \"lo2\": float(lon[-1, -1]),\n",
    "        \"la2\": float(lat[-1, -1]),\n",
    "        \"dx\": float((lon[0, -1] - lon[0, 0]) / (nx - 1)),\n",
    "        \"dy\": float((lat[0, 0] - lat[-1, 0]) / (ny - 1)),\n",
    "        \"refTime\": \"2024-02-19 00:00:00\",\n",
    "        \"forecastTime\": 0\n",
    "    },\n",
    "    \"uComponent\": u10.values.flatten().tolist(),\n",
    "    \"vComponent\": v10.values.flatten().tolist()\n",
    "}\n",
    "\n",
    "# Save to JSON\n",
    "with open(\"wind_velocity.json\", \"w\") as f:\n",
    "    json.dump(data, f)\n",
    "\n",
    "print(\"✅ wind_velocity.json created without wrf-python.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c61e2d02-d656-4243-8a81-430e28bef89e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ wind_velocity.json created with both eastward and northward wind components.\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "# Load WRF NetCDF file\n",
    "ds = xr.open_dataset(\"/Users/manaruchi/Desktop/WeatherDataViz/raw_data/AFCNWP_WRF_model_output_00UTC.nc\")\n",
    "\n",
    "# Extract U10 and V10 (10 m winds)\n",
    "u10 = ds[\"U10\"].isel(Time=0)\n",
    "v10 = ds[\"V10\"].isel(Time=0)\n",
    "lat = ds[\"XLAT\"].isel(Time=0)\n",
    "lon = ds[\"XLONG\"].isel(Time=0)\n",
    "\n",
    "# Convert from m/s to knots\n",
    "u10_knots = u10.values * 1.94384\n",
    "v10_knots = v10.values * 1.94384\n",
    "\n",
    "ny, nx = u10.shape\n",
    "\n",
    "# Shared header metadata\n",
    "base_header = {\n",
    "    \"parameterUnit\": \"KT\",\n",
    "    \"parameterCategory\": 2,\n",
    "    \"nx\": nx,\n",
    "    \"ny\": ny,\n",
    "    \"lo1\": float(lon[0, 0]),\n",
    "    \"la1\": float(lat[0, 0]),\n",
    "    \"lo2\": float(lon[-1, -1]),\n",
    "    \"la2\": float(lat[-1, -1]),\n",
    "    \"dx\": float((lon[0, -1] - lon[0, 0]) / (nx - 1)),\n",
    "    \"dy\": float((lat[0, 0] - lat[-1, 0]) / (ny - 1)),\n",
    "    \"refTime\": \"2024-05-01 00:00:00\",\n",
    "    \"forecastTime\": 0\n",
    "}\n",
    "\n",
    "# Create two objects: eastward and northward winds\n",
    "eastward = {\n",
    "    \"header\": {**base_header, \"parameterNumber\": 2, \"parameterNumberName\": \"eastward_wind\"},\n",
    "    \"data\": u10_knots.flatten().tolist()\n",
    "}\n",
    "\n",
    "northward = {\n",
    "    \"header\": {**base_header, \"parameterNumber\": 3, \"parameterNumberName\": \"northward_wind\"},\n",
    "    \"data\": v10_knots.flatten().tolist()\n",
    "}\n",
    "\n",
    "# Combine into one array (expected by Leaflet Velocity)\n",
    "combined = [eastward, northward]\n",
    "\n",
    "# Write to file\n",
    "with open(\"wind_velocity.json\", \"w\") as f:\n",
    "    json.dump(combined, f)\n",
    "\n",
    "print(\"✅ wind_velocity.json created with both eastward and northward wind components.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38b3c5a-5c57-44f0-927d-4abc8a0622ec",
   "metadata": {},
   "source": [
    "# Prepare Winds JSON for multiple heights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "57b485e0-b11b-43a7-a705-7806cb35e5e5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unable to avoid copy while creating an array as requested.\nIf using `np.array(obj, copy=False)` replace it with `np.asarray(obj)` to allow a copy when needed (no behavior change in NumPy 1.x).\nFor more details, see https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 67\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m vectorized_interp(var_rev, p_rev)\n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m# Convert time for header\u001b[39;00m\n\u001b[0;32m---> 67\u001b[0m time_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[43mds\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTimes\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTime\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTIME_STEP_INDEX\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m)\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(time_str, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[1;32m     69\u001b[0m     time_str \u001b[38;5;241m=\u001b[39m time_str\u001b[38;5;241m.\u001b[39mdecode()\n",
      "File \u001b[0;32m/opt/miniconda3/envs/myenv/lib/python3.9/site-packages/xarray/core/dataarray.py:801\u001b[0m, in \u001b[0;36mDataArray.values\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mvalues\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[1;32m    790\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    791\u001b[0m \u001b[38;5;124;03m    The array's data converted to numpy.ndarray.\u001b[39;00m\n\u001b[1;32m    792\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    799\u001b[0m \u001b[38;5;124;03m    to this array may be reflected in the DataArray as well.\u001b[39;00m\n\u001b[1;32m    800\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 801\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/myenv/lib/python3.9/site-packages/xarray/core/variable.py:541\u001b[0m, in \u001b[0;36mVariable.values\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    538\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    539\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mvalues\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    540\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"The variable's data as a numpy.ndarray\"\"\"\u001b[39;00m\n\u001b[0;32m--> 541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_as_array_or_item\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/myenv/lib/python3.9/site-packages/xarray/core/variable.py:339\u001b[0m, in \u001b[0;36m_as_array_or_item\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_as_array_or_item\u001b[39m(data):\n\u001b[1;32m    326\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the given values as a numpy array, or as an individual item if\u001b[39;00m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;124;03m    it's a 0d datetime64 or timedelta64 array.\u001b[39;00m\n\u001b[1;32m    328\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;124;03m    TODO: remove this (replace with np.asarray) once these issues are fixed\u001b[39;00m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 339\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    340\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    341\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m data\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mM\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m/opt/miniconda3/envs/myenv/lib/python3.9/site-packages/xarray/core/indexing.py:834\u001b[0m, in \u001b[0;36mMemoryCachedArray.__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    833\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__array__\u001b[39m(\u001b[38;5;28mself\u001b[39m, dtype: np\u001b[38;5;241m.\u001b[39mtyping\u001b[38;5;241m.\u001b[39mDTypeLike \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[0;32m--> 834\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39masarray(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_duck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/myenv/lib/python3.9/site-packages/xarray/core/indexing.py:837\u001b[0m, in \u001b[0;36mMemoryCachedArray.get_duck_array\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    836\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_duck_array\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 837\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ensure_cached\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    838\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39marray\u001b[38;5;241m.\u001b[39mget_duck_array()\n",
      "File \u001b[0;32m/opt/miniconda3/envs/myenv/lib/python3.9/site-packages/xarray/core/indexing.py:831\u001b[0m, in \u001b[0;36mMemoryCachedArray._ensure_cached\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_ensure_cached\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 831\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39marray \u001b[38;5;241m=\u001b[39m as_indexable(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_duck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/myenv/lib/python3.9/site-packages/xarray/core/indexing.py:788\u001b[0m, in \u001b[0;36mCopyOnWriteArray.get_duck_array\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    787\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_duck_array\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 788\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_duck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/myenv/lib/python3.9/site-packages/xarray/core/indexing.py:647\u001b[0m, in \u001b[0;36mLazilyIndexedArray.get_duck_array\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    645\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_duck_array\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    646\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39marray, ExplicitlyIndexedNDArrayMixin):\n\u001b[0;32m--> 647\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43mapply_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    648\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    649\u001b[0m         \u001b[38;5;66;03m# If the array is not an ExplicitlyIndexedNDArrayMixin,\u001b[39;00m\n\u001b[1;32m    650\u001b[0m         \u001b[38;5;66;03m# it may wrap a BackendArray so use its __getitem__\u001b[39;00m\n\u001b[1;32m    651\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39marray[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey]\n",
      "File \u001b[0;32m/opt/miniconda3/envs/myenv/lib/python3.9/site-packages/xarray/core/indexing.py:1030\u001b[0m, in \u001b[0;36mapply_indexer\u001b[0;34m(indexable, indexer)\u001b[0m\n\u001b[1;32m   1028\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m indexable\u001b[38;5;241m.\u001b[39moindex[indexer]\n\u001b[1;32m   1029\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1030\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mindexable\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/myenv/lib/python3.9/site-packages/xarray/coding/strings.py:263\u001b[0m, in \u001b[0;36mStackedBytesArray.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key\u001b[38;5;241m.\u001b[39mtuple[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mslice\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    262\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoo many indices\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 263\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_numpy_char_to_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/myenv/lib/python3.9/site-packages/xarray/coding/strings.py:214\u001b[0m, in \u001b[0;36m_numpy_char_to_bytes\u001b[0;34m(arr)\u001b[0m\n\u001b[1;32m    212\u001b[0m copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m HAS_NUMPY_2_0 \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;66;03m# based on: http://stackoverflow.com/a/10984878/809705\u001b[39;00m\n\u001b[0;32m--> 214\u001b[0m arr \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    215\u001b[0m dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(arr\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mview(dtype)\u001b[38;5;241m.\u001b[39mreshape(arr\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n",
      "\u001b[0;31mValueError\u001b[0m: Unable to avoid copy while creating an array as requested.\nIf using `np.array(obj, copy=False)` replace it with `np.asarray(obj)` to allow a copy when needed (no behavior change in NumPy 1.x).\nFor more details, see https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword."
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "\n",
    "# ---------- CONFIG ----------\n",
    "INPUT_FILE = \"/Users/manaruchi/Desktop/WeatherDataViz/raw_data/AFCNWP_WRF_model_output_00UTC.nc\"\n",
    "OUTPUT_DIR = \"/Users/manaruchi/Desktop/WeatherDataViz/raw_data\"\n",
    "DOWNSAMPLE_STEP = 3        # Downsampling grid stride\n",
    "TIME_STEP_INDEX = 0        # Change this to choose the timestep to export\n",
    "PRESSURE_LEVELS = [100000, 92500, 85000, 70000, 60000, 50000, 30000, 20000, 10000, 5000]  # Pa\n",
    "# ----------------------------\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Load dataset\n",
    "ds = xr.open_dataset(INPUT_FILE)\n",
    "\n",
    "# Read variables\n",
    "U_stag = ds[\"U\"]         # (Time, bottom_top, south_north, west_east_stag)\n",
    "V_stag = ds[\"V\"]         # (Time, bottom_top, south_north_stag, west_east)\n",
    "P = ds[\"P\"]              # perturbation pressure\n",
    "PB = ds[\"PB\"]            # base state pressure\n",
    "PH = ds[\"PH\"]            # perturbation geopotential\n",
    "PHB = ds[\"PHB\"]          # base geopotential\n",
    "XLAT = ds[\"XLAT\"]        # latitude (Time, south_north, west_east)\n",
    "XLONG = ds[\"XLONG\"]      # longitude (Time, south_north, west_east)\n",
    "\n",
    "# Unstagger U and V for chosen time step\n",
    "U = 0.5 * (U_stag[TIME_STEP_INDEX, :, :, :-1] + U_stag[TIME_STEP_INDEX, :, :, 1:])\n",
    "V = 0.5 * (V_stag[TIME_STEP_INDEX, :, :-1, :] + V_stag[TIME_STEP_INDEX, :, 1:, :])\n",
    "\n",
    "# Total pressure (Pa)\n",
    "pressure = P + PB  # (Time, bottom_top, south_north, west_east)\n",
    "pressure = pressure[TIME_STEP_INDEX]\n",
    "\n",
    "# Geopotential height in meters (optional)\n",
    "g = 9.81\n",
    "height = (PH + PHB)[TIME_STEP_INDEX] / g\n",
    "\n",
    "# Latitude and longitude for chosen time step and downsampled grid\n",
    "lat = XLAT[TIME_STEP_INDEX]\n",
    "lon = XLONG[TIME_STEP_INDEX]\n",
    "\n",
    "lat_ds = lat[::DOWNSAMPLE_STEP, ::DOWNSAMPLE_STEP].values\n",
    "lon_ds = lon[::DOWNSAMPLE_STEP, ::DOWNSAMPLE_STEP].values\n",
    "\n",
    "nx = lon_ds.shape[1]\n",
    "ny = lat_ds.shape[0]\n",
    "\n",
    "# Helper: interpolate variable (shape [level, y, x]) to a target pressure level (scalar) by linear interpolation\n",
    "def interpolate_to_pressure(var3d, pressure3d, target_pressure):\n",
    "    \"\"\"\n",
    "    Interpolate variable var3d (shape: level, y, x) to target pressure level\n",
    "    var3d and pressure3d have matching dimensions.\n",
    "    \"\"\"\n",
    "    levels, ny, nx = var3d.shape\n",
    "    var_interp = np.full((ny, nx), np.nan)\n",
    "\n",
    "    # Reverse vertical axis (levels) so pressure is increasing for np.interp\n",
    "    var_rev = var3d[::-1, :, :]\n",
    "    p_rev = pressure3d[::-1, :, :]\n",
    "\n",
    "    for j in range(ny):\n",
    "        for i in range(nx):\n",
    "            try:\n",
    "                var_profile = var_rev[:, j, i]\n",
    "                p_profile = p_rev[:, j, i]\n",
    "                var_interp[j, i] = np.interp(target_pressure, p_profile, var_profile)\n",
    "            except Exception as e:\n",
    "                # If interpolation fails, leave NaN\n",
    "                var_interp[j, i] = np.nan\n",
    "\n",
    "    return var_interp\n",
    "\n",
    "\n",
    "# Convert time for header\n",
    "time_str = str(ds[\"Times\"].isel(Time=TIME_STEP_INDEX).values)\n",
    "if isinstance(time_str, bytes):\n",
    "    time_str = time_str.decode()\n",
    "\n",
    "time_iso = time_str.replace(\" \", \"T\") + \"Z\"\n",
    "\n",
    "for p_pa in PRESSURE_LEVELS:\n",
    "    label = f\"{int(p_pa/100)}hPa\"\n",
    "    print(f\"Processing {label} ...\")\n",
    "\n",
    "    # Interpolate U and V winds to this pressure level\n",
    "    u_interp = interpolate_to_pressure(U.values, pressure.values, p_pa)\n",
    "    v_interp = interpolate_to_pressure(V.values, pressure.values, p_pa)\n",
    "\n",
    "    # Downsample to reduce size\n",
    "    u_ds = u_interp[::DOWNSAMPLE_STEP, ::DOWNSAMPLE_STEP]\n",
    "    v_ds = v_interp[::DOWNSAMPLE_STEP, ::DOWNSAMPLE_STEP]\n",
    "\n",
    "    # Build data array: [u0, v0, u1, v1, ...]\n",
    "    data = []\n",
    "    for i in range(ny):\n",
    "        for j in range(nx):\n",
    "            u_val = float(u_ds[i, j])\n",
    "            v_val = float(v_ds[i, j])\n",
    "            # For leaflet-velocity, data is [u0, v0, u1, v1, ...]\n",
    "            data.append(u_val)\n",
    "            data.append(v_val)\n",
    "\n",
    "    # Leaflet-velocity header\n",
    "    header = {\n",
    "        \"parameterCategory\": 2,\n",
    "        \"parameterNumber\": 2,\n",
    "        \"parameterNumberName\": \"Eastward wind\",\n",
    "        \"level\": label,\n",
    "        \"date\": time_iso,\n",
    "        \"nx\": nx,\n",
    "        \"ny\": ny,\n",
    "        \"dx\": float(abs(lon_ds[0,1] - lon_ds[0,0])),\n",
    "        \"dy\": float(abs(lat_ds[1,0] - lat_ds[0,0])),\n",
    "        \"la1\": float(lat_ds[-1,0]),  # southernmost lat\n",
    "        \"lo1\": float(lon_ds[-1,0]),  # westernmost lon\n",
    "        \"la2\": float(lat_ds[0,-1]),  # northernmost lat\n",
    "        \"lo2\": float(lon_ds[0,-1])   # easternmost lon\n",
    "    }\n",
    "\n",
    "    json_obj = {\n",
    "        \"header\": header,\n",
    "        \"data\": data\n",
    "    }\n",
    "\n",
    "    output_file = os.path.join(OUTPUT_DIR, f\"wind_{label}.json\")\n",
    "    with open(output_file, \"w\") as f:\n",
    "        json.dump(json_obj, f)\n",
    "\n",
    "    print(f\"Saved {output_file}\")\n",
    "\n",
    "print(\"All done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18e530b7-1e0e-4a33-bac7-cb6eb21fa6e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 66)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_ds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398f7e28-5eb2-47cb-9e2a-f39d6b457453",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
